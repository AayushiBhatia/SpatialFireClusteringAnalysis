# -*- coding: utf-8 -*-
"""Entire April FF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kzSyNlO01OU7s9lObmYIc2GXBV7SZefa
"""

import pandas as pd
import numpy as np
import itertools
from sklearn.neighbors import NearestNeighbors
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from scipy.spatial import ConvexHull

path = "/content/drive/MyDrive/NSSTC/Fires/2021_04_forestfires.csv"

data = pd.read_csv(path)
data.head(10)

scaler = MinMaxScaler()
scaler.fit(data)
dfs1 = scaler.transform(data)
dfs1 = pd.DataFrame(dfs1)

dfs1.head()

print(dfs1.shape)
print('------------------------------------------------')
print(dfs1.isnull().sum())
print('------------------------------------------------')
print(dfs1.describe())

#determining the episilon value by calculating the average distance between each point
#in the data set and its 6 nearest neighbors (2 * its dimension)

neighbors = NearestNeighbors(n_neighbors=20)
neighbors_fit = neighbors.fit(dfs1)
distances, indices = neighbors_fit.kneighbors(dfs1)

distances = np.sort(distances, axis=0)
plt.plot(distances);

distances = np.sort(distances, axis=0)
plt.xlim([30000, 55000])
plt.ylim([0, 0.08])
plt.grid(which='major')
plt.plot(distances);

#eps1=[0.03,0.035,0.04,0.045,0.05,0.055,0.06,0.065,0.07]
eps1=[0.03,0.035,0.04,0.045,0.05,0.055,0.06,0.065,0.07,0.075,0.08]
minpts1=[270,275,280,285]


sil_score1=[]  # empty array for storage
num_clus1 = []


for ep, minpt in itertools.product(eps1,minpts1):


    print(ep,minpt)

    db_clus1 = DBSCAN(eps=ep, min_samples= minpt).fit(dfs1)



    if len(np.unique(db_clus1.labels_)) == 1:
        sil_score1.append(-1)


    else:
        sil_score1.append(silhouette_score(dfs1, db_clus1.labels_))
    num_clus1.append(len(np.unique(db_clus1.labels_)))

res1 = pd.DataFrame(list(itertools.product(eps1,minpts1)))
res1 ['silhouette_score'] = sil_score1
res1 ['num_cluster'] = num_clus1
res1.sort_values (by = 'silhouette_score' , ascending = False)

res1.sort_values (by = 'silhouette_score' , ascending = False).head(20)

ds1 = DBSCAN (eps= 0.075, min_samples=275).fit(dfs1)
data['DBSCAN_Clusters'] = ds1.labels_

p = sns.scatterplot(data = data, x = "DBSCAN_Clusters", y = "FRP", hue = ds1.labels_, legend = "full", palette = "deep")
sns.move_legend(p, "upper right", bbox_to_anchor = (1.17, 1.), title = 'Clusters')
plt.show()

data.head(10)

outliers_df = data[ds1.labels_ == -1]
clusters_df = data[ds1.labels_ != -1]

colors = ds1.labels_
col_clus = colors[colors != -1]
col_outliers = 'black'

clusters = Counter(ds1.labels_)
print(clusters)
print(data[ds1.labels_==-1].head(10))
print ('Number of Clusters = {}'.format(len(clusters)-1))

clusters_df.to_csv(r'/content/drive/MyDrive/NSSTC/Fires/Clusters/MayAg_clusters.csv\AprilFF_clusters.csv', index=False)

fig = plt.figure()

ax = fig.add_axes([0.1, 0.1, 1,1])

ax.scatter(clusters_df['LONGITUDE'], clusters_df['LATITUDE'], c=col_clus, edgecolors = 'black', s=50)
ax.scatter(outliers_df['LONGITUDE'], outliers_df['LATITUDE'], c=col_outliers, edgecolors = 'black', s=50)


ax.set_xlabel('LONGITUDE')
ax.set_ylabel('LATITUDE')

#plt.grid(which='major')

plt.show()

fig = plt.figure()

ax = fig.add_axes([0.1, 0.1, 1,1])

ax.scatter(clusters_df['LONGITUDE'], clusters_df['LATITUDE'], c=col_clus, edgecolors = 'black', s=50)

for i in data.DBSCAN_Clusters.unique():
    points = data[data.DBSCAN_Clusters == i][['LATITUDE', 'LONGITUDE']].values
    hull = ConvexHull(points)



ax.set_xlabel('LONGITUDE')
ax.set_ylabel('LATITUDE')

#plt.grid(which='major')

plt.show()

a =data.DBSCAN_Clusters.unique()
s=np.delete(data.DBSCAN_Clusters.unique(), np.where(a == -1))
print(a)
print(s)

fig = plt.figure()

ax = fig.add_axes([0.1, 0.1, 1,1])

ax.scatter(clusters_df['LONGITUDE'], clusters_df['LATITUDE'], c=col_clus, edgecolors = 'black', s=50)

# ax.scatter(outliers_df['LONGITUDE'], outliers_df['LATITUDE'], c=col_outliers, edgecolors = 'black', s=50)

a =data.DBSCAN_Clusters.unique()
s=np.delete(data.DBSCAN_Clusters.unique(), np.where(a == -1))

for i in s:
    points = data[data.DBSCAN_Clusters == i][['LATITUDE', 'LONGITUDE']].values

    hull = ConvexHull(points)

    vert = np.append(hull.vertices,hull.vertices[0])  # close the polygon by appending the first point at the end

    ax.plot(points[vert, 1], points[vert,0 ], '--')
    ax.fill(points[vert, 1], points[vert, 0], alpha=0.2)

ax.set_xlabel('LONGITUDE')
ax.set_ylabel('LATITUDE')

#plt.grid(which='major')

plt.show()

fig = plt.figure()

ax = fig.add_axes([4, 4, 6, 10])

ax.scatter(clusters_df['LONGITUDE'], clusters_df['LATITUDE'], c=col_clus, edgecolors = 'black', s=70)
#ax.scatter(outliers_df['LONGITUDE'], outliers_df['LATITUDE'], c=col_outliers, edgecolors = 'black', s=50)

a =data.DBSCAN_Clusters.unique()
s=np.delete(data.DBSCAN_Clusters.unique(), np.where(a == -1))

for i in s:
    points = data[data.DBSCAN_Clusters == i][['LATITUDE', 'LONGITUDE']].values
    points = data[data.DBSCAN_Clusters == i][['LATITUDE', 'LONGITUDE']].values
    # get convex hull
    hull = ConvexHull(points)


    vert = np.append(hull.vertices, hull.vertices[0])  # close the polygon by appending the first point at the end
    ax.plot(points[vert, 1], points[vert, 0], '--')
    ax.fill(points[vert, 1], points[vert, 0], alpha=0.2)


ax.set_xlabel('LONGITUDE')
ax.set_ylabel('LATITUDE')

#plt.grid(which='major')

plt.show()